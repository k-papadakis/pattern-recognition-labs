{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T19:08:58.892079Z","iopub.status.busy":"2022-01-16T19:08:58.891750Z","iopub.status.idle":"2022-01-16T19:09:02.260474Z","shell.execute_reply":"2022-01-16T19:09:02.259669Z","shell.execute_reply.started":"2022-01-16T19:08:58.892003Z"},"trusted":true},"outputs":[],"source":["import os\n","import pickle\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import librosa\n","import librosa.display\n","from sklearn.metrics import classification_report\n","import torch\n","from torch import nn\n","from torch import optim\n","from torch.nn.utils.rnn import pad_sequence, pad_packed_sequence, pack_padded_sequence, PackedSequence\n","from torch.utils.data import Dataset, Subset, DataLoader, random_split\n","\n","RANDOM_STATE = 42\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T19:09:02.263034Z","iopub.status.busy":"2022-01-16T19:09:02.262549Z","iopub.status.idle":"2022-01-16T19:09:02.283780Z","shell.execute_reply":"2022-01-16T19:09:02.283142Z","shell.execute_reply.started":"2022-01-16T19:09:02.262997Z"},"trusted":true},"outputs":[],"source":["class_mapping = {\n","    'Rock': 'Rock',\n","    'Psych-Rock': 'Rock',\n","    'Indie-Rock': None,\n","    'Post-Rock': 'Rock',\n","    'Psych-Folk': 'Folk',\n","    'Folk': 'Folk',\n","    'Metal': 'Metal',\n","    'Punk': 'Metal',\n","    'Post-Punk': None,\n","    'Trip-Hop': 'Trip-Hop',\n","    'Pop': 'Pop',\n","    'Electronic': 'Electronic',\n","    'Hip-Hop': 'Hip-Hop',\n","    'Classical': 'Classical',\n","    'Blues': 'Blues',\n","    'Chiptune': 'Electronic',\n","    'Jazz': 'Jazz',\n","    'Soundtrack': None,\n","    'International': None,\n","    'Old-Time': None\n","}\n","\n","\n","def read_fused_spectrogram(spectrogram_file):\n","    spectrogram = np.load(spectrogram_file)\n","    return spectrogram.T\n","\n","def read_mel_spectrogram(spectrogram_file):\n","    spectrogram = np.load(spectrogram_file)[:128]\n","    return spectrogram.T\n","\n","def read_chromagram(spectrogram_file):\n","    spectrogram = np.load(spectrogram_file)[128:]\n","    return spectrogram.T\n","\n","# I will implement the DataSets differently, so that they load the data on demand,\n","# instead of preloading everything and filling precious memory.\n","# Also, perform padding on batch creation and split our datasets using torch's random_split.\n","\n","class SpectrogramDataset(Dataset):\n","    def __init__(self, path, read_spec_fn, class_mapping, train=True):\n","        self.class_mapping = class_mapping\n","        self.read_spec_fn = read_spec_fn\n","        t = 'train' if train else 'test'\n","        self.data_dir = os.path.join(path, t)\n","        self.labels_file = os.path.join(path, f'{t}_labels.txt')\n","        data_files, labels_str = self.get_file_labels()\n","        self.data_files = np.array(data_files)\n","        self.labels_str, self.labels = np.unique(labels_str, return_inverse=True)\n","        \n","    def get_file_labels(self):\n","        data_files = []\n","        labels = []\n","        with open(self.labels_file) as f:\n","            next(f)  # Skip the headers\n","            for line in f:\n","                line = line.rstrip()\n","                t, label = line.split('\\t')\n","                if self.class_mapping is not None:\n","                    label = self.class_mapping[label]\n","                if label is None:\n","                    continue\n","                t, _ = t.split('.', 1)\n","                data_file = f'{t}.fused.full.npy'\n","                data_files.append(data_file)\n","                labels.append(label)\n","        return data_files, labels\n","    \n","    def __len__(self):\n","        return len(self.labels)\n","    \n","    def __getitem__(self, index):\n","        x = self.read_spec_fn(os.path.join(self.data_dir, self.data_files[index]))\n","        y = self.labels[index]\n","        return torch.Tensor(x), torch.LongTensor([y]), torch.LongTensor([len(x)])\n","\n","\n","def split_dataset(dataset, train_size, seed=RANDOM_STATE):\n","    n = len(dataset)\n","    n_train = int(train_size * n)\n","    n_val = n - n_train\n","    generator = torch.Generator()\n","    if seed is not None:\n","        generator.manual_seed(seed)\n","    dataset_train, dataset_val = random_split(dataset, [n_train, n_val], generator)\n","    return dataset_train, dataset_val\n","\n","\n","def collate_fn(batch):\n","    seqs, labels, lengths = map(list, zip(*batch))\n","    return pad_sequence(seqs, batch_first=True), torch.LongTensor(labels), torch.LongTensor(lengths)\n","\n","\n","def plot_spectograms(spec1, spec2, title1=None, title2=None, suptitle=None, cmap='viridis'):\n","    fig, axs = plt.subplots(2, figsize=(9, 12))\n","    img = librosa.display.specshow(spec1, ax=axs[0], cmap=cmap)\n","    librosa.display.specshow(spec2, ax=axs[1], cmap=cmap)\n","    axs[0].set_title(title1)\n","    axs[1].set_title(title2)\n","    fig.colorbar(img, ax=axs)\n","    fig.suptitle(suptitle)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T19:09:02.286115Z","iopub.status.busy":"2022-01-16T19:09:02.285645Z","iopub.status.idle":"2022-01-16T19:09:02.388941Z","shell.execute_reply":"2022-01-16T19:09:02.388319Z","shell.execute_reply.started":"2022-01-16T19:09:02.286080Z"},"trusted":true},"outputs":[],"source":["# Prepare all datasets and loaders\n","raw_path = '/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms'\n","\n","fused_raw_train_full = SpectrogramDataset(raw_path, read_spec_fn=read_fused_spectrogram, train=True, class_mapping=class_mapping)\n","fused_raw_train, fused_raw_val = split_dataset(fused_raw_train_full, train_size=0.8)\n","fused_raw_test = SpectrogramDataset(raw_path, read_spec_fn=read_fused_spectrogram, train=False, class_mapping=class_mapping)\n","\n","mel_raw_train_full = SpectrogramDataset(raw_path, read_spec_fn=read_mel_spectrogram, train=True, class_mapping=class_mapping)\n","mel_raw_train, mel_raw_val = split_dataset(mel_raw_train_full, train_size=0.8)\n","mel_raw_test = SpectrogramDataset(raw_path, read_spec_fn=read_mel_spectrogram, train=False, class_mapping=class_mapping)\n","\n","chroma_raw_train_full = SpectrogramDataset(raw_path, read_spec_fn=read_chromagram, train=True, class_mapping=class_mapping)\n","chroma_raw_train, chroma_raw_val = split_dataset(chroma_raw_train_full, train_size=0.8)\n","chroma_raw_test = SpectrogramDataset(raw_path, read_spec_fn=read_chromagram, train=False, class_mapping=class_mapping)\n","\n","beat_path = '/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat'\n","\n","fused_beat_train_full = SpectrogramDataset(beat_path, read_spec_fn=read_fused_spectrogram, train=True, class_mapping=class_mapping)\n","fused_beat_train, fused_beat_val = split_dataset(fused_beat_train_full, train_size=0.8)\n","fused_beat_test = SpectrogramDataset(beat_path, read_spec_fn=read_fused_spectrogram, train=False, class_mapping=class_mapping)\n","\n","mel_beat_train_full = SpectrogramDataset(beat_path, read_spec_fn=read_mel_spectrogram, train=True, class_mapping=class_mapping)\n","mel_beat_train, mel_beat_val = split_dataset(mel_beat_train_full, train_size=0.8)\n","mel_beat_test = SpectrogramDataset(beat_path, read_spec_fn=read_mel_spectrogram, train=False, class_mapping=class_mapping)\n","\n","chroma_beat_train_full = SpectrogramDataset(beat_path, read_spec_fn=read_chromagram, train=True, class_mapping=class_mapping)\n","chroma_beat_train, chroma_beat_val = split_dataset(chroma_beat_train_full, train_size=0.8)\n","chroma_beat_test = SpectrogramDataset(beat_path, read_spec_fn=read_chromagram, train=False, class_mapping=class_mapping)\n","\n","labels = mel_raw_train_full.labels\n","labels_str = mel_raw_train_full.labels_str"]},{"cell_type":"markdown","metadata":{},"source":["In our example we chose Electronic music vs classical music.\n","We see that the Electronic sample is more tightly structured in a disrete manner, while Classical sample is more fluid and continuous,\n","and this holds both for the mel spectogram and the chromogram.\n","Also, from the mel spectograms we see that the Electronic sample has harmonics over the entire frequency range,\n","while the Classical sample does not. Finaly notice the regular vertical lines in the Electronic samples\n","which are a result of a regular rhythm\n","\n","As we see, size of each raw sample is above 150,000 which is almost impossible to use for training on normal machines.\n","On the other hand beat-synced samples have size of roughly 750, which is definitely something we can work with."]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T19:09:02.391390Z","iopub.status.busy":"2022-01-16T19:09:02.390896Z","iopub.status.idle":"2022-01-16T19:09:04.249239Z","shell.execute_reply":"2022-01-16T19:09:04.248536Z","shell.execute_reply.started":"2022-01-16T19:09:02.391350Z"},"trusted":true},"outputs":[],"source":["def step_0_1_2_3():\n","    label1_str = 'Electronic'\n","    label2_str = 'Classical'\n","    label1 = labels_str.tolist().index(label1_str)\n","    label2 = labels_str.tolist().index(label2_str)\n","    index1 = labels.tolist().index(label1)\n","    index2 = labels.tolist().index(label2)\n","\n","    for dataset, spec_type, transform in zip(\n","            (mel_raw_train_full, chroma_raw_train, mel_beat_train_full, chroma_beat_train_full),\n","            ('Mel frequencies', 'Chromagrams')*2,\n","            ('Raw',)*2 + ('Beat-Synced',)*2\n","        ):\n","        spec1 = dataset[index1][0].numpy()\n","        spec2 = dataset[index2][0].numpy()\n","        print(f'{spec_type} ({transform}) shape: {spec1.shape}')\n","        plot_spectograms(spec1.T, spec2.T, label1_str, label2_str, f'{spec_type} ({transform})')\n","    \n","    \n","step_0_1_2_3()"]},{"cell_type":"markdown","metadata":{},"source":["As noted earlier I implemented the Datasets differently.\n","Below I answer the questions asked in the original implementation.\n","\n","* QUESTION: Comment on howv the train and validation splits are created.\n","\n","  ANSWER: We read the data in arrays, create an array of the indices,\n","  we shuffle the indices, and then we split them.\n","\n","* QUESTION: It's useful to set the seed when debugging but when experimenting ALWAYS set seed=None. Why?\n","\n","  ANSWER: Because we would always be training and validating on the same data,\n","  which could make the model learn properties specific to that split\n","  and which aren't properties of the entire set.\n","\n","* QUESTION: Comment on why padding is needed\n","\n","  ANSWER: Because PyTorch doesn't support ragged tensors.\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T19:09:04.251523Z","iopub.status.busy":"2022-01-16T19:09:04.251049Z","iopub.status.idle":"2022-01-16T19:09:04.841846Z","shell.execute_reply":"2022-01-16T19:09:04.841038Z","shell.execute_reply.started":"2022-01-16T19:09:04.251480Z"},"trusted":true},"outputs":[],"source":["def step_4():\n","    # Create a dataset without using the class mapping, solely for computing the labels\n","    # Note that constructing the dataset is cheap, since our implementation is lazy.\n","    ds = SpectrogramDataset(raw_path, read_spec_fn=read_mel_spectrogram, train=True, class_mapping=None)\n","    labels_str_original = ds.labels_str\n","    labels_original = ds.labels\n","\n","    fig, axs = plt.subplots(ncols=2, figsize=(12, 8))\n","    sns.histplot(labels_str_original[labels_original], bins=len(labels_str_original), ax=axs[0])\n","    sns.histplot(labels_str[labels], bins=len(labels_str), ax=axs[1])\n","    _ = plt.setp(axs[0].get_xticklabels(), rotation=45, ha='right')\n","    _ = plt.setp(axs[1].get_xticklabels(), rotation=45, ha='right')\n","    axs[0].set_title('Original Labels')\n","    axs[1].set_title('Transformed Labels')\n","\n","    \n","step_4()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T19:09:04.843884Z","iopub.status.busy":"2022-01-16T19:09:04.843599Z","iopub.status.idle":"2022-01-16T19:09:04.875003Z","shell.execute_reply":"2022-01-16T19:09:04.874141Z","shell.execute_reply.started":"2022-01-16T19:09:04.843847Z"},"trusted":true},"outputs":[],"source":["class CustomLSTM(nn.Module):\n","    \n","    def __init__(self, input_size, hidden_size, output_size,\n","                 bidirectional=False, dropout=0.\n","                 ):\n","        super().__init__()\n","        self.lstm = nn.LSTM(input_size, hidden_size,\n","                            bidirectional=bidirectional, batch_first=True)\n","        self.linear = nn.Linear(hidden_size * (bidirectional + 1), output_size)\n","        self.dropout = nn.Dropout(p=dropout)\n","        \n","    def forward(self, x, lengths):\n","        \n","        lstm_out, *_ = self.lstm(x)\n","        if isinstance(lstm_out, PackedSequence):\n","            lstm_out, _ = pad_packed_sequence(lstm_out, batch_first=True)\n","        \n","        # Get the final outputs of each direction and concatenate them\n","        end_indices = (lengths - 1)[..., None, None].to(DEVICE)\n","        end1 = torch.take_along_dim(lstm_out[..., :self.lstm.hidden_size],\n","                                    end_indices,\n","                                    1\n","                                    ).squeeze()\n","        end2 = torch.take_along_dim(lstm_out[..., self.lstm.hidden_size:],\n","                                    end_indices,\n","                                    1\n","                                    ).squeeze()\n","        # If self.lstm.bidirectional, end2 is an empty tensor\n","        lstm_out = torch.cat((end1, end2), dim=-1)\n","    \n","        dropout_out = self.dropout(lstm_out)\n","        linear_out = self.linear(dropout_out)\n","        return linear_out\n","\n","\n","def train_loop(dataloader, model, loss_fn, optimizer, device=DEVICE):\n","    model.train()\n","    train_loss = 0.\n","    n_batches = len(dataloader)\n","    \n","    for x, y, lengths in dataloader:\n","        x, y = x.to(device), y.to(device)\n","        x = pack_padded_sequence(x, lengths, enforce_sorted=False, batch_first=True)\n","        \n","        # Compute prediction and loss\n","        pred = model(x, lengths)\n","        loss = loss_fn(pred, y)\n","        train_loss += loss.item()\n","\n","        # Backpropagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","    train_loss /= n_batches\n","    return train_loss\n","\n","\n","def test_loop(dataloader, model, loss_fn, device=DEVICE):\n","    model.eval()\n","    n_batches = len(dataloader)\n","    test_loss = 0\n","    test_accuracy = 0\n","\n","    with torch.inference_mode():\n","        for x, y, lengths in dataloader:\n","            x, y = x.to(device), y.to(device)\n","            x = pack_padded_sequence(x, lengths, enforce_sorted=False, batch_first=True)\n","            probs = model(x, lengths)\n","            test_loss += loss_fn(probs, y).item()\n","            preds = torch.argmax(probs, 1)\n","            test_accuracy += (preds == y).float().mean().item()\n","\n","    test_loss /= n_batches\n","    test_accuracy /= n_batches\n","    return test_loss, test_accuracy\n","\n","\n","def train_eval(model, train_dataset, val_dataset, batch_size,epochs,\n","               lr=1e-3, l2=1e-2, patience=5, tolerance=1e-3,\n","               save_path='best-model.pth', overfit_batch=False,\n","               ):\n","    \n","    \n","    if overfit_batch:\n","        k = 1\n","        # Create a subset of the dataset of size k*batch_size and use this instead\n","        rng = np.random.default_rng(seed=RANDOM_STATE)\n","        indices = rng.choice(np.arange(len(train_dataset)), size=k*batch_size, replace=False)\n","        train_dataset = Subset(train_dataset, indices)\n","        # Increase the number of epochs appropriately\n","        # total = epochs * len(dataset)\n","        #       = epochs * n_batches * batch_size\n","        #       = epochs * n_batches * k * (batch_size/k)\n","        # Thus, to keep roughly same total we do:\n","        epochs *= (batch_size // k) + 1\n","        # But we will use at most 200 epochs\n","        epochs = min(epochs, 200)\n","        print(f'Overfit Batch mode. The dataset now comprises of only {k} Batches. '\n","              f'Epochs increased to {epochs}.')\n","        \n","    \n","    \n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn,\n","                              pin_memory=True, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn,\n","                            pin_memory=True)\n","\n","    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=l2)\n","    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n","    loss_fn = nn.CrossEntropyLoss()\n","\n","    train_losses = []\n","    val_losses = []\n","    val_accuracies = []\n","\n","    best_val_loss = float('+infinity')\n","    waiting = 0\n","\n","    for t in range(epochs):\n","        # Train and validate\n","        print(f'----EPOCH {t}----')\n","        train_loss = train_loop(train_loader, model, loss_fn, optimizer)\n","        print(f'Train Loss: {train_loss}')\n","        \n","        # Validating is not usefull in overfit_batch mode.\n","        # We also won't use the scheduler in over_fit batch mode\n","        # because the epoch numbers become too large.\n","        if not overfit_batch:\n","            val_loss, val_accuracy = test_loop(val_loader, model, loss_fn)\n","            print(f'Val Loss: {val_loss}')\n","            print(f'Val Accuracy: {val_accuracy}')\n","            \n","            # Save the best model\n","            if val_loss < best_val_loss:\n","                best_val_loss = val_loss\n","                torch.save(model, save_path)\n","                print('Saving')\n","                \n","            # Early Stopping\n","            if val_losses and val_losses[-1] - val_loss < tolerance:\n","                if waiting == patience:\n","                    print('Early Stopping')\n","                    break\n","                waiting += 1\n","                print(f'waiting = {waiting}')\n","            else:\n","                waiting = 0\n","        \n","            scheduler.step()\n","        \n","        train_losses.append(train_loss)\n","        if not overfit_batch:\n","            val_losses.append(val_loss)\n","            val_accuracies.append(val_accuracy)\n","        print()\n","        \n","    return train_losses, val_losses, val_accuracies"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T19:09:04.877410Z","iopub.status.busy":"2022-01-16T19:09:04.876987Z","iopub.status.idle":"2022-01-16T19:09:04.895795Z","shell.execute_reply":"2022-01-16T19:09:04.894435Z","shell.execute_reply.started":"2022-01-16T19:09:04.877372Z"},"trusted":true},"outputs":[],"source":["# The parameters in the following were chosen so that they work well with overfit_batch=True\n","\n","def train_mel_raw(overfit_batch=False):\n","    train_dataset = mel_raw_train\n","    val_dataset = mel_raw_val\n","    input_dim = train_dataset[0][0].shape[1]\n","    output_dim = len(labels_str)\n","    model = CustomLSTM(input_dim, 512, output_dim, bidirectional=True, dropout=0.2).to(DEVICE)\n","\n","    losses = train_eval(model, train_dataset, val_dataset,\n","                    batch_size=128, epochs=50, lr=1e-3,\n","                    overfit_batch=overfit_batch, save_path='best-mel-raw.pth')\n","    if not overfit_batch:\n","        with open('losses-mel-raw.pkl', 'wb') as f:\n","            pickle.dump(losses, f)\n","\n","\n","def train_mel_beat(overfit_batch=False):\n","    train_dataset = mel_beat_train\n","    val_dataset = mel_beat_val\n","    input_dim = train_dataset[0][0].shape[1]\n","    output_dim = len(labels_str)\n","    model = CustomLSTM(input_dim, 256, output_dim, bidirectional=True, dropout=0.1).to(DEVICE)\n","\n","    losses = train_eval(model, train_dataset, val_dataset,\n","                    batch_size=512, epochs=200, lr=1e-3,\n","                    overfit_batch=overfit_batch, save_path='best-mel-beat.pth')\n","    if not overfit_batch:\n","        with open('losses-mel-beat.pkl', 'wb') as f:\n","            pickle.dump(losses, f)\n","    \n","\n","def train_chroma_raw(overfit_batch=False):\n","    train_dataset = chroma_raw_train\n","    val_dataset = chroma_raw_val\n","    input_dim = train_dataset[0][0].shape[1]\n","    output_dim = len(labels_str)\n","    model = CustomLSTM(input_dim, 128, output_dim, bidirectional=True, dropout=0.1).to(DEVICE)\n","\n","    losses = train_eval(model, train_dataset, val_dataset,\n","                    batch_size=256, epochs=50, lr=1e-3,\n","                    overfit_batch=overfit_batch, save_path='best-chroma-raw.pth')\n","    if not overfit_batch:\n","        with open('losses-chroma-raw.pkl', 'wb') as f:\n","            pickle.dump(losses, f)\n","\n","\n","def train_fused_raw(overfit_batch=False):\n","    train_dataset = fused_raw_train\n","    val_dataset = fused_raw_val\n","    input_dim = train_dataset[0][0].shape[1]\n","    output_dim = len(labels_str)\n","    model = CustomLSTM(input_dim, 512, output_dim, bidirectional=True, dropout=0.2).to(DEVICE)\n","\n","    losses = train_eval(model, train_dataset, val_dataset,\n","                    batch_size=128, epochs=50, lr=1e-3,\n","                    overfit_batch=overfit_batch, save_path='best-fused-raw.pth')\n","    if not overfit_batch:\n","        with open('losses-fused-raw.pkl', 'wb') as f:\n","            pickle.dump(losses, f)\n","\n","            \n","def train_fused_beat(overfit_batch=False):\n","    train_dataset = fused_beat_train\n","    val_dataset = fused_beat_val\n","    input_dim = train_dataset[0][0].shape[1]\n","    output_dim = len(labels_str)\n","    model = CustomLSTM(input_dim, 256, output_dim, bidirectional=True, dropout=0.1).to(DEVICE)\n","\n","    losses = train_eval(model, train_dataset, val_dataset,\n","                    batch_size=512, epochs=200, lr=1e-3,\n","                    overfit_batch=overfit_batch, save_path='best-fused-beat.pth')\n","    if not overfit_batch:\n","        with open('losses-fused-beat.pkl', 'wb') as f:\n","            pickle.dump(losses, f)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T19:09:04.898046Z","iopub.status.busy":"2022-01-16T19:09:04.897655Z","iopub.status.idle":"2022-01-16T19:09:04.912182Z","shell.execute_reply":"2022-01-16T19:09:04.911357Z","shell.execute_reply.started":"2022-01-16T19:09:04.897897Z"},"trusted":true},"outputs":[],"source":["def predict(test_dataset, model, batch_size=128, device=DEVICE):\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn,\n","                             pin_memory=True)\n","    res = []\n","    with torch.inference_mode():\n","        for x, y, lengths in test_loader:\n","            x, y = x.to(device), y.to(device)\n","            probs = model(x, lengths)\n","            preds = torch.argmax(probs, 1)\n","            res.append(preds)\n","    return torch.cat(res, 0).cpu()\n","\n","\n","def report(model, test_dataset):\n","    y_true = test_dataset.labels\n","    y_pred = predict(test_dataset, model)\n","    print(classification_report(y_true, y_pred, zero_division=0))\n","    \n","\n","def plot_learning_curves(path):\n","    with open(path, 'rb') as f:\n","        train_losses, val_losses, _ = pickle.load(f)\n","    fig, ax = plt.subplots(figsize=(9, 9))\n","    ax.plot(train_losses, label='Training Loss')\n","    ax.plot(val_losses, label='Validation Loss')\n","    name = path.split('.', 1)[0]\n","    ax.set_title(f'Learning Curves for {name}')\n","    ax.legend()"]},{"cell_type":"code","execution_count":9,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2022-01-16T19:09:04.914250Z","iopub.status.busy":"2022-01-16T19:09:04.913788Z","iopub.status.idle":"2022-01-16T19:45:23.799585Z","shell.execute_reply":"2022-01-16T19:45:23.798801Z","shell.execute_reply.started":"2022-01-16T19:09:04.914214Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["def step_5_6():\n","    train_mel_raw(overfit_batch=False)\n","    train_mel_beat(overfit_batch=False)\n","    train_chroma_raw(overfit_batch=False)\n","    train_fused_raw(overfit_batch=False)\n","    train_fused_beat(overfit_batch=False)\n","    \n","    model_mel_raw = torch.load('best-mel-raw.pth')\n","    model_mel_beat = torch.load('best-mel-beat.pth')\n","    model_chroma_raw = torch.load('best-chroma-raw.pth')\n","    model_fused_raw = torch.load('best-fused-raw.pth')\n","    model_fused_beat = torch.load('best-fused-beat.pth')\n","    \n","    print('Mel raw')\n","    report(model_mel_raw, mel_raw_test)\n","    print('\\n\\n')\n","    print('Mel beat-sync')\n","    report(model_mel_beat, mel_beat_test)\n","    print('\\n\\n')\n","    print('Chroma raw')\n","    report(model_chroma_raw, chroma_raw_test)\n","    print('\\n\\n')\n","    print('Fused raw')\n","    report(model_fused_raw, fused_raw_test)\n","    print('\\n\\n')\n","    print('Fused beat')\n","    report(model_fused_beat, fused_beat_test)\n","\n","\n","step_5_6()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-01-16T19:55:38.941206Z","iopub.status.busy":"2022-01-16T19:55:38.940926Z","iopub.status.idle":"2022-01-16T19:55:39.391263Z","shell.execute_reply":"2022-01-16T19:55:39.390559Z","shell.execute_reply.started":"2022-01-16T19:55:38.941174Z"},"trusted":true},"outputs":[],"source":["plot_learning_curves('losses-fused-beat.pkl')"]},{"cell_type":"markdown","metadata":{},"source":["To calculate precision, recall and f1 of a class C, we view the our problem as a binary classification problem, with C being the positive class and all the other classes comprising the negative class.\n","Then we have,\n","* **Precision**: True Positives / (True Positives + False Positives). \n","\n","  Precision is the ability of the classifier not to label as positive a sample that is negative.\n","* **Recall**: True Positives / (True Positives + False Negatives). \n","\n","  Recall is the ability of the classifier to find all the positive samples.\n","* **F1**: True Positives / (True Positives + (False Positives + False Negatives)/2). \n","\n","  F1 is a mix of recall and precision. Instead of picking either False Positives or False Negatives, we just pick their average.\n","\n","When we consider all the classes we have\n","* **Accuracy**: correct_predictions / predictions\n","\n","and then we can generalize the inherently binary metrics Precision, Recall and F1, by averaging them in one of the following ways:\n","\n","* **Macro**: Simply taking the mean of the results\n","* **Weighted**: Take the *weighted* mean of the results using class frequencies as weights.\n","* **Micro**: We consider all the True Positives, all the False Positives and all the False Negatives of all classes, and we use their sums to calculate Precision, Recall and F1. Note that micro F1 is the same as Accuracy (if each sample belongs to exactly one class), since (False Positives + False Negatives) / 2 = Number of misclassified data (a false negative for one class is a false postive for another, meaning we double-count).\n","\n","\n","In our case, all classes are equally important, so we should use their weighted average instead of the simple macro. Micro average is also a good global metric in our case.\n","\n","In F1 score can be low when either the precision or recall are low. F1 differs from Accuracy mainly when the classes are imbalanced. For example consider that we have 90 negative samples and 10 positive ones, and a classifier which predicts everything correctly except fot 10 negative samples. In that case TP=10, FP=0, FN=10 and we have Accuracy = 9/10 and F1 = 2/3.\n","\n","Micro F1 vs Macro F1 is essentially a generalization of Accuracy vs F1 in a multilabel setting. Micro F1 is equal to Accuracy (if each sample belongs to exactly one class), while the Macro F1 average the F1 scores for each class giving every class equal weight. This means that if heavily underrepresented class will influence the macro F1 as much as the other class, but it won't influence the micro F1.\n","\n","Different problems require different metrics.\n","* We need high recall for problems where catching every positive is important, for example, identifying a severe desease, even at the cost of giving many false positives.\n","* We need high precision for problems where we false positives are costly. For example we don't want to classify an important email as spam, even at the cost of giving letting some spam go to the inbox."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
